{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82333da-6e27-4715-961e-3aeb32c29331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:53:02.082628Z",
     "start_time": "2021-10-05T15:53:00.188991Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from joblib import Parallel, delayed\n",
    "from skimage import exposure, io\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4742f7e5-5171-4382-895a-8509e56917b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T15:53:02.148567Z",
     "start_time": "2021-10-05T15:53:02.143604Z"
    }
   },
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "data_dir = p_dir / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2485e25-4fcc-4561-8b79-b9c4a5842ef0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795e5969-9203-4c68-97b4-d5aeeba3e1ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:03:47.635704Z",
     "start_time": "2021-10-05T16:03:47.623743Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_info(img_folder):\n",
    "    \"\"\"Function returns the info from folder containing multi-cycle staigning on cell\n",
    "\n",
    "    Args:\n",
    "        img_folder (str) : imgage folder path to get information\n",
    "        name_dict (dict) : three level dictionnary mapping cycle -> channel -> marker name\n",
    "\n",
    "    Returns:\n",
    "        pandas dataframe with information\n",
    "    \"\"\"\n",
    "    rois = []\n",
    "    images_path = []\n",
    "    markers = []\n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(img_folder):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tiff\" not in name or 'Mask' in name:\n",
    "                continue\n",
    "\n",
    "            roi = dirpath.split(\"_\")[-1]\n",
    "            try:\n",
    "                marker = name.split(\"_\")[2].split(\".\")[0]\n",
    "                if marker == \"contaminant\":\n",
    "                    continue\n",
    "                elif marker == \"DNA\":\n",
    "                    if \"191Ir\" in name:\n",
    "                        marker += \"1\"\n",
    "                    else:\n",
    "                        marker += \"2\"\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            path = os.path.join(dirpath, name)\n",
    "            rois.append(roi)\n",
    "            markers.append(marker)\n",
    "            images_path.append(path)\n",
    "\n",
    "    info = {\n",
    "        \"ROI\": rois,\n",
    "        \"Marker\": markers,\n",
    "        \"Path\": images_path,\n",
    "    }\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fb7ac5-821d-49ce-bcf5-fa03ecb40ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:04:38.206950Z",
     "start_time": "2021-10-05T16:04:38.141945Z"
    }
   },
   "outputs": [],
   "source": [
    "donors = [\n",
    "    \"LN Donor A\",\n",
    "    \"LN Donor E\",\n",
    "    \"INT Donor B\",\n",
    "    \"INT Donor E\",\n",
    "    \"TS Donor A\",\n",
    "    \"TS Donor E\",\n",
    "    \"SP Donor A\"\n",
    "]\n",
    "\n",
    "donor = donors[-2]\n",
    "df = get_info(data_dir / 'ROI_images' /donor)\n",
    "df.to_csv(data_dir / \"metadata\" / f\"info_{donor}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936a51e7-38ca-4d3f-b60c-49bd3e1b95c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:04:38.401949Z",
     "start_time": "2021-10-05T16:04:38.389947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROI</th>\n",
       "      <th>Marker</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CD38</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vimentin</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CD21</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>BCL6</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ICOS1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>18</td>\n",
       "      <td>CD27</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>18</td>\n",
       "      <td>EZH2</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>18</td>\n",
       "      <td>H3K27me3</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>18</td>\n",
       "      <td>DNA1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>18</td>\n",
       "      <td>DNA2</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROI    Marker                                               Path\n",
       "0     1      CD38  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "1     1  Vimentin  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "2     1      CD21  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "3     1      BCL6  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "4     1     ICOS1  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "..   ..       ...                                                ...\n",
       "463  18      CD27  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "464  18      EZH2  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "465  18  H3K27me3  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "466  18      DNA1  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "467  18      DNA2  Y:\\coskun-lab\\Thomas\\Leap\\data\\ROI_images\\TS D...\n",
       "\n",
       "[468 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20ec1c-a8af-4df0-b5c3-c9421904826e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a9f776-2c2d-4fdf-8678-0f84946bf5a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:04:39.607955Z",
     "start_time": "2021-10-05T16:04:39.596952Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "def get_NN(data, n):\n",
    "    fit = NearestNeighbors(n_neighbors=n).fit(data)\n",
    "    distances, indices = fit.kneighbors(data)\n",
    "\n",
    "    return distances, indices\n",
    "\n",
    "\n",
    "def filter_img_knn(img, n=25, th=3.5):\n",
    "    # Get avg distances per positive expressed pixels\n",
    "    x, y = np.where(img > 0)\n",
    "    values = img[x, y]\n",
    "\n",
    "    data = np.column_stack((x, y))\n",
    "    distances, indices = get_NN(data, n)\n",
    "    # avg_dist = np.average(distances, axis=1, weights=values[indices])\n",
    "    avg_dist = np.average(distances, axis=1)\n",
    "\n",
    "    filter_ind = avg_dist > th\n",
    "    unique, counts = np.unique(filter_ind, return_counts=True)\n",
    "    print(unique, counts)\n",
    "    x_fil = x[filter_ind]\n",
    "    y_fil = y[filter_ind]\n",
    "\n",
    "    img_fil = img.copy()\n",
    "    img_fil[x_fil, y_fil] = 0\n",
    "\n",
    "    return img_fil\n",
    "\n",
    "\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        chunk_shape = (1,) + data_shape[1:]\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=chunk_shape,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def contrast_streching(img):\n",
    "    img = img[:1000, :1000]\n",
    "    p2, p98 = np.percentile(img, (0.1, 99.9))\n",
    "    img = exposure.rescale_intensity(img, in_range=(p2, p98), out_range=(0, 255)).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def read_img(path):\n",
    "    # return contrast_streching(skimage.io.imread(path))\n",
    "    return skimage.io.imread(path)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aba16025-4eb2-4294-bfcb-82bb0e51e1c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T16:05:10.714166Z",
     "start_time": "2021-10-05T16:04:39.769954Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 exists\n",
      "Dataset 10 exists\n",
      "Dataset 11 exists\n",
      "Dataset 12 exists\n",
      "Dataset 13 exists\n",
      "Dataset 14 exists\n",
      "Dataset 15 exists\n",
      "Dataset 16 exists\n",
      "Dataset 2 exists\n",
      "Dataset 3 exists\n",
      "Dataset 4 exists\n",
      "Dataset 5 exists\n",
      "Dataset 6 exists\n",
      "Dataset 7 exists\n",
      "Dataset 8 exists\n",
      "Dataset 9 exists\n",
      "Dataset 1 exists\n",
      "Dataset 10 exists\n",
      "Dataset 11 exists\n",
      "Dataset 12 exists\n",
      "Dataset 13 exists\n",
      "Dataset 14 exists\n",
      "Dataset 15 exists\n",
      "Dataset 2 exists\n",
      "Dataset 3 exists\n",
      "Dataset 4 exists\n",
      "Dataset 5 exists\n",
      "Dataset 6 exists\n",
      "Dataset 7 exists\n",
      "Dataset 8 exists\n",
      "Dataset 9 exists\n",
      "Dataset 1 exists\n",
      "Dataset 10 exists\n",
      "Dataset 11 exists\n",
      "Dataset 12 exists\n",
      "Dataset 13 exists\n",
      "Dataset 14 exists\n",
      "Dataset 15 exists\n",
      "Dataset 16 exists\n",
      "Dataset 17 exists\n",
      "Dataset 18 exists\n",
      "Dataset 19 exists\n",
      "Dataset 2 exists\n",
      "Dataset 20 exists\n",
      "Dataset 3 exists\n",
      "Dataset 4 exists\n",
      "Dataset 5 exists\n",
      "Dataset 6 exists\n",
      "Dataset 7 exists\n",
      "Dataset 8 exists\n",
      "Dataset 9 exists\n",
      "Dataset 1 exists\n",
      "Dataset 10 exists\n",
      "Dataset 11 exists\n",
      "Dataset 12 exists\n",
      "Dataset 13 exists\n",
      "Dataset 14 exists\n",
      "Dataset 15 exists\n",
      "Dataset 16 exists\n",
      "Dataset 2 exists\n",
      "Dataset 3 exists\n",
      "Dataset 4 exists\n",
      "Dataset 5 exists\n",
      "Dataset 6 exists\n",
      "Dataset 7 exists\n",
      "Dataset 8 exists\n",
      "Dataset 9 exists\n",
      "Dataset 1 exists\n",
      "Dataset 10 exists\n",
      "Dataset 11 exists\n",
      "Dataset 12 exists\n",
      "Dataset 13 exists\n",
      "Dataset 14 exists\n",
      "Dataset 2 exists\n",
      "Dataset 3 exists\n",
      "Dataset 4 exists\n",
      "Dataset 5 exists\n",
      "Dataset 6 exists\n",
      "Dataset 7 exists\n",
      "Dataset 8 exists\n",
      "Dataset 9 exists\n",
      "Dataset 1 exists\n",
      "Dataset 10 exists\n",
      "Dataset 11 exists\n",
      "Dataset 12 exists\n",
      "Dataset 13 exists\n",
      "Dataset 14 exists\n",
      "Dataset 15 exists\n",
      "Dataset 16 exists\n",
      "Dataset 17 exists\n",
      "Dataset 18 exists\n",
      "Dataset 2 exists\n",
      "Dataset 3 exists\n",
      "Dataset 4 exists\n",
      "Dataset 5 exists\n",
      "Dataset 6 exists\n",
      "Dataset 7 exists\n",
      "Dataset 8 exists\n",
      "Dataset 9 exists\n"
     ]
    }
   ],
   "source": [
    "# Loop through datasets\n",
    "for donor in donors:\n",
    "    # Get info DF used for clustering\n",
    "    df = get_info(data_dir /'ROI_images' / donor)\n",
    "    \n",
    "    # Define saving location\n",
    "    h5_data = p_dir / \"data\" / \"h5_new\" / f\"{donor}.hdf5\"\n",
    "    \n",
    "    # Loops through ROIs\n",
    "    group = df.groupby(\"ROI\")\n",
    "    for name, df_group in group:\n",
    "        paths = df_group.Path.tolist()\n",
    "        imgs_raw = joblib_loop(read_img, paths)\n",
    "        imgs = joblib_loop(filter_img_knn, imgs_raw)\n",
    "        markers = df_group.Marker.tolist()\n",
    "        imgs = np.stack(imgs, axis=0)\n",
    "        save_hdf5(h5_data, name, imgs, {\"labels\": markers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2c7dc9-92b4-4ec1-8c4c-b2830fa49b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import napari\n",
    "\n",
    "# viewer = napari.view_image(imgs, channel_axis=0, name=markers, visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2906985e-e831-47cb-aa0e-e4b2511e0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import napari\n",
    "\n",
    "# viewer = napari.view_image(np.stack(imgs_raw, axis=0), channel_axis=0, name=markers, visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39424a-cca5-4ca5-bc00-d876c3d7605e",
   "metadata": {},
   "source": [
    "# Stitch Images from position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0b8918-4ce5-44ba-b80f-39218bb9e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "def get_imgs(file_path, name):\n",
    "    f = h5py.File(file_path, \"r\")\n",
    "    imgs = f[name]\n",
    "    labels = list(f[name].attrs[\"labels\"])\n",
    "    return imgs, labels\n",
    "\n",
    "def get_img_size(roi_dict, size=1000):\n",
    "    row_max = 0\n",
    "    col_max = 0\n",
    "    for k, v in roi_dict.items():\n",
    "        row_max = max(row_max, v[0])\n",
    "        col_max = max(col_max, v[1])\n",
    "    return row_max + size, col_max + size\n",
    "\n",
    "def get_img_subset(imgs, markers, labels):\n",
    "    imgs_subset = []\n",
    "    for marker in markers:\n",
    "        idx = labels.index(marker)\n",
    "        imgs_subset.append(imgs[idx])\n",
    "    return np.stack(imgs_subset, axis=2)\n",
    "\n",
    "def contrast_streching(img):\n",
    "    p2, p98 = np.percentile(img, (0.1, 99.9))\n",
    "    img = exposure.rescale_intensity(img, in_range=(p2, p98), out_range=(0, 255)).astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e15758-e4c6-418f-9e3e-eb8c21130e5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Format row, col\n",
    "arrangement = {\n",
    "    \"LN Donor A\": {\n",
    "        1: [0, 1000],\n",
    "        2: [0, 2000],\n",
    "        3: [1000, 0],\n",
    "        4: [1000, 1000],\n",
    "        5: [1000, 2000],\n",
    "        6: [1000, 3000],\n",
    "        7: [2000, 0],\n",
    "        8: [2000, 1000],\n",
    "        9: [2000, 2000],\n",
    "        10: [2000, 3000],\n",
    "        11: [3000, 0],\n",
    "        12: [3000, 1000],\n",
    "        13: [3000, 2000],\n",
    "        14: [3000, 3000],\n",
    "        15: [4000, 1000],\n",
    "        16: [4000, 2000],\n",
    "    },\n",
    "    \"LN Donor E\": {\n",
    "        1: [1000, 0],\n",
    "        2: [1000, 1000],\n",
    "        3: [1000, 2000],\n",
    "        4: [1000, 3000],\n",
    "        5: [1000, 4000],\n",
    "        6: [1000, 5000],\n",
    "        7: [1000, 6000],\n",
    "        8: [1000, 7000],\n",
    "        9: [1000, 8000],\n",
    "        10: [0, 0],\n",
    "        11: [0, 1000],\n",
    "        12: [0, 2000],\n",
    "        13: [0, 3000],\n",
    "        14: [0, 4000],\n",
    "    },\n",
    "    \"INT Donor B\": {\n",
    "        1: [0, 0],\n",
    "        2: [0, 1000],\n",
    "        3: [1000, 0],\n",
    "        4: [1000, 1000],\n",
    "        5: [2000, 0],\n",
    "        6: [2000, 1000],\n",
    "        7: [2000, 2000],\n",
    "        8: [2000, 3000],\n",
    "        9: [3000, 0],\n",
    "        10: [3000, 1000],\n",
    "        11: [3000, 2000],\n",
    "        12: [3000, 3000],\n",
    "        13: [4000, 0],\n",
    "        14: [4000, 1000],\n",
    "        15: [4000, 2000],\n",
    "        16: [4000, 3000],\n",
    "        17: [5000, 0],\n",
    "        18: [5000, 1000],\n",
    "        19: [5000, 2000],\n",
    "        20: [5000, 3000],\n",
    "    },\n",
    "    \"INT Donor E\": {\n",
    "        1: [0, 0],\n",
    "        2: [0, 1000],\n",
    "        3: [0, 2000],\n",
    "        4: [0, 3000],\n",
    "        # 5: [0, 4000],\n",
    "        6: [1000, 0],\n",
    "        7: [1000, 1000],\n",
    "        8: [1000, 2000],\n",
    "        9: [1000, 3000],\n",
    "        10: [1000, 4000],\n",
    "        11: [2000, 3000],\n",
    "        12: [2000, 4000],\n",
    "        13: [3000, 3000],\n",
    "        14: [3000, 4000],\n",
    "        15: [4000, 3000],\n",
    "        16: [4000, 4000],\n",
    "    },\n",
    "    \"TS Donor A\": {\n",
    "        1: [0, 0],\n",
    "        2: [0, 1000],\n",
    "        3: [0, 2000],\n",
    "        4: [0, 3000],\n",
    "        5: [0, 4000],\n",
    "        6: [0, 5000],\n",
    "        7: [0, 6000],\n",
    "        8: [1000, 0],\n",
    "        9: [1000, 1000],\n",
    "        10: [1000, 2000],\n",
    "        11: [1000, 3000],\n",
    "        12: [1000, 4000],\n",
    "        13: [1000, 5000],\n",
    "        14: [1000, 6000],\n",
    "    },\n",
    "    \"TS Donor E\": {\n",
    "        1: [0, 0],\n",
    "        2: [0, 1000],\n",
    "        3: [0, 2000],\n",
    "        4: [1000, 0],\n",
    "        5: [1000, 1000],\n",
    "        6: [1000, 2000],\n",
    "        7: [2000, 0],\n",
    "        8: [2000, 1000],\n",
    "        9: [2000, 2000],\n",
    "        10: [3000, 0],\n",
    "        11: [3000, 1000],\n",
    "        12: [3000, 2000],\n",
    "        13: [4000, 0],\n",
    "        14: [4000, 1000],\n",
    "        15: [4000, 2000],\n",
    "        16: [5000, 0],\n",
    "        17: [5000, 1000],\n",
    "        18: [5000, 2000],\n",
    "    },\n",
    "    \"SP Donor A\": {\n",
    "        1: [0, 0],\n",
    "        2: [0, 1000],\n",
    "        3: [0, 2000],\n",
    "        4: [0, 3000],\n",
    "        5: [0, 4000],\n",
    "        6: [1000, 0],\n",
    "        7: [1000, 1000],\n",
    "        8: [1000, 2000],\n",
    "        9: [1000, 3000],\n",
    "        10: [1000, 4000],\n",
    "        11: [2000, 0],\n",
    "        12: [2000, 1000],\n",
    "        13: [2000, 2000],\n",
    "        14: [2000, 3000],\n",
    "        15: [2000, 4000],\n",
    "        16: [3000, 0],\n",
    "        17: [3000, 1000],\n",
    "        18: [3000, 2000],\n",
    "        19: [3000, 3000],\n",
    "        20: [3000, 4000],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67014b10-aa06-4b32-933f-2e472fed27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['CD38',\n",
    " 'Vimentin',\n",
    " 'CD21',\n",
    " 'BCL6',\n",
    " 'ICOS1',\n",
    " 'CD11b',\n",
    " 'CD86',\n",
    " 'CXCR4',\n",
    " 'CD11c',\n",
    " 'FoxP3',\n",
    " 'CD4',\n",
    " 'CD138',\n",
    " 'CXCR5',\n",
    " 'CD20',\n",
    " 'CD8',\n",
    " 'C-Myc',\n",
    " 'PD1',\n",
    " 'CD83',\n",
    " 'Ki67',\n",
    " 'COL1',\n",
    " 'CD3',\n",
    " 'CD27',\n",
    " 'EZH2',\n",
    " 'H3K27me3',\n",
    " 'DNA1',\n",
    " 'DNA2']\n",
    "\n",
    "size = 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f903662-ef53-4a86-b099-4e380699ecba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7338be93f3654b91a0fb28002dca90ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for donor in donors[4:-1]:\n",
    "    h5_data = p_dir / \"data\" / \"h5_new\" / f\"{donor}.hdf5\"\n",
    "\n",
    "    # Create combined images\n",
    "    y_max, x_max = get_img_size(arrangement[donor])\n",
    "    img_combined = np.zeros((y_max, x_max, len(markers)), dtype=np.uint8)\n",
    "\n",
    "    ROIs = [i for i in range(1, 21)]\n",
    "    for roi in tqdm(ROIs):\n",
    "        if roi not in arrangement[donor].keys():\n",
    "            continue\n",
    "\n",
    "        # Read imgs\n",
    "        imgs, labels = get_imgs(h5_data, str(roi))\n",
    "\n",
    "        # Get multiplex image\n",
    "        data = get_img_subset(imgs, markers, labels)\n",
    "\n",
    "        # Insert Combined images\n",
    "        y = arrangement[donor][roi][0]\n",
    "        x = arrangement[donor][roi][1]\n",
    "        img_combined[y : y + size, x : x + size, :] = data\n",
    "\n",
    "    # save_path = (\n",
    "    #     p_dir / \"figures\" / \"multiplex\" / f\"combined_{donor}_{markers_subset}.png\"\n",
    "    # )\n",
    "    # img_combined = Image.fromarray(img_combined)\n",
    "    # img_combined.save(save_path)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788ed904-a28e-475e-a610-6262921efcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LN Donor A', 'LN Donor E', 'INT Donor B', 'INT Donor E', 'TS Donor A', 'TS Donor E', 'SP Donor A']\n"
     ]
    }
   ],
   "source": [
    "print(donors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee86de9-e68f-47a5-9071-a1c4631318fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389aa6ef251547d7bfb942c9053db6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "donor = donors[2]\n",
    "h5_data = p_dir / \"data\" / \"h5_new\" / f\"{donor}.hdf5\"\n",
    "\n",
    "# Create combined images\n",
    "y_max, x_max = get_img_size(arrangement[donor])\n",
    "img_combined = np.zeros((y_max, x_max, len(markers)), dtype=np.uint8)\n",
    "\n",
    "ROIs = [i for i in range(1, 21)]\n",
    "for roi in tqdm(ROIs):\n",
    "    if roi not in arrangement[donor].keys():\n",
    "        continue\n",
    "\n",
    "    # Read imgs\n",
    "    imgs, labels = get_imgs(h5_data, str(roi))\n",
    "\n",
    "    # Get multiplex image\n",
    "    data = get_img_subset(imgs, markers, labels)\n",
    "\n",
    "    # Insert Combined images\n",
    "    y = arrangement[donor][roi][0]\n",
    "    x = arrangement[donor][roi][1]\n",
    "    img_combined[y : y + size, x : x + size, :] = data[:1000,:1000]\n",
    "\n",
    "for i in range(img_combined.shape[2]):\n",
    "    img_combined[...,i] = contrast_streching(img_combined[...,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fe65090-25f9-414e-b12b-1a9640f7b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [labels.index(m) for m in ['DNA1', 'DNA2']]\n",
    "img_dapi = np.max(img_combined[:1000,:1000,indices], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cc68d34-33fc-464e-94a9-ad9df00096ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'Y:\\\\coskun-lab\\\\Thomas\\\\CellSeg\\\\data\\\\LEAP\\\\bestFocus\\\\{donor}.tif'\n",
    "skimage.io.imsave(save_path, img_dapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5c996c-025d-4467-88d8-a4bcc569acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# with open(r'Y:\\coskun-lab\\Thomas\\CellSeg\\data\\LEAP\\channelNames.txt', 'w') as fp:\n",
    "#     for item in labels:\n",
    "#         # write each item on a new line\n",
    "#         fp.write(\"%s\\n\" % item)\n",
    "#     print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46895061-c1b9-4b0e-a5c1-f58d539a2e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 5000, 26)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56e4fe-7a72-4120-a743-94f4055c0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "napari.view_image(np.stack(img_combined), channel_axis=2, name=labels, visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05bf0b-db48-4ed5-a346-6f21f75d9341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-scanpy]",
   "language": "python",
   "name": "conda-env-.conda-scanpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
